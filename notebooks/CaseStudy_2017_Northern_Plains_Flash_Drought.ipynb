{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79bde19-ec9b-401e-8ad0-6bfad1ad6dc3",
   "metadata": {},
   "source": [
    "# Case Study: 2017 Northern Plains Flash Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c13a88-9869-4dad-8384-e863e384589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot\n",
    "\n",
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7b524-c0a6-46d7-9a8c-255d2a9a5c55",
   "metadata": {},
   "source": [
    "## Before We Get Started\n",
    "\n",
    "For this case study, we're going to download some data from [the North American Land Data Assimilation System (NLDAS).](https://disc.gsfc.nasa.gov/datasets/NLDAS_NOAH0125_M_2.0/summary?keywords=NLDAS)\n",
    "\n",
    "Consequently, we'll need a place to store these raw data. It's important that we have a folder in our file system reserved for these raw data so we can keep them separate from any new datasets we might create. \n",
    "\n",
    "**Let's create a folder called `data_raw` in our Jupyter Notebook's file system.**\n",
    "\n",
    "We should never modify the raw data (that we're about to download). Doing so would make it hard to repeat the analysis we're going to perform as we will lose the original data values. This doesn't mean we have to keep the `data_raw` folder around forever: if it's publicly available data, we can always download it again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22575e4c-dada-4ebe-8d8e-67b5f55fc39d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cde0a-21a3-4a6d-bc78-78aa58b51804",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for year in range(2008, 2018):\n",
    "    search = earthaccess.search_data(\n",
    "        short_name = 'NLDAS_NOAH0125_M',\n",
    "        version = '2.0',\n",
    "        temporal = (f'{year}-09', f'{year}-09'))\n",
    "    results.extend(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f8847-6347-4ad7-8179-de355a4ba781",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12eab9d-a5d7-4eef-8191-140c30c037e8",
   "metadata": {},
   "source": [
    "Previously, we've used `earthaccess.open()` to get access to these data. This time, we'll use `earthaccess.download()`. What's the difference?\n",
    "\n",
    "- `earthaccess.open()` provides a file-like object that is available to be downloaded and read *only we need it.*\n",
    "- `earthaccess.download()` actually downloads the file to our file system.\n",
    "\n",
    "**Note that, below, we're telling `earthaccess.download()` to put the downloaded files into our new `data_raw` folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3692c6-ae6c-4f6d-b919-747917eb9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.download(results, 'data_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f97ffe-29fe-4a4c-9c14-555aedd29d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "file_list = glob.glob('data_raw/*.nc')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f86436-943d-4e04-afb4-eef26b55efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "\n",
    "# Open just the first file\n",
    "nc = netCDF4.Dataset(file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad44b04-3ef4-4497-b056-7b8568156123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Discuss file-level metadata\n",
    "\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfff4f-9a2a-486a-a89d-44a477612ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Discuss file-level metadata\n",
    "# TODO Discuss \"scale_factor\" and \"add_offset\" and \"missing_value\"\n",
    "\n",
    "et = nc.variables['Evap']\n",
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0e2bd-12db-432f-af8c-f684d98b73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note the shape\n",
    "# TODO Note the orientation\n",
    "# TODO Discuss CF convention\n",
    "\n",
    "pyplot.imshow(et[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dd59c-b288-41c3-818c-2039cda5c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(np.flipud(et[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087afd3f-99d7-45f0-8454-518ca4eb479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Note data type, why we're changing it to an array\n",
    "\n",
    "type(et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dab3e-a300-4284-8e56-f6967eb331d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_series = []\n",
    "\n",
    "for filename in file_list:\n",
    "    nc = netCDF4.Dataset(filename)\n",
    "    et = np.array(nc.variables['Evap'])\n",
    "    # Don't forget to to flip the image upside-down!\n",
    "    et_series.append(np.flipud(et[0]))\n",
    "\n",
    "et_series = np.stack(et_series, axis = 0)\n",
    "et_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094b6e3-21c6-43a2-8257-6d998d4843c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computing a Climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b5090-84d5-4dc7-9115-71f70d7d987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO define a climatology\n",
    "\n",
    "et_clim = et_series.mean(axis = 0)\n",
    "et_clim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a994a3-f797-40ec-984c-8aed3dee14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(et_clim)\n",
    "pyplot.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c32075-89bc-4c5a-b3b8-a84042338fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NoData\n",
    "\n",
    "et_clim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2949fe-b779-4009-8b26-52e807693bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_clim[et_clim < 0] = np.nan\n",
    "\n",
    "pyplot.imshow(et_clim)\n",
    "cbar = pyplot.colorbar()\n",
    "cbar.set_label('Evapotranspiration [kg m-2]')\n",
    "pyplot.title('Mean September ET')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778d73f-1c62-45d4-99fa-650972f0a9c4",
   "metadata": {},
   "source": [
    "### How Does September 2017 Compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd8479-61eb-4cf6-9550-556df714f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76515bd-32a7-4a9e-9335-43566d6e19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_2017_anomaly = et_series[-1] - et_clim\n",
    "\n",
    "pyplot.imshow(et_2017_anomaly, cmap = 'RdYlBu')\n",
    "cbar = pyplot.colorbar()\n",
    "cbar.set_label('Evapotranspiration Anomaly [kg m-2]')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69040f-e17b-4168-bea9-b703014e1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [\n",
    "    nc.variables['lon'][:].min(),\n",
    "    nc.variables['lon'][:].max(),\n",
    "    nc.variables['lat'][:].min(),\n",
    "    nc.variables['lat'][:].max()\n",
    "]\n",
    "extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f587d-58fb-4e91-a9e4-4f895f00047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "shapename = 'admin_1_states_provinces_lakes'\n",
    "states_shp = shpreader.natural_earth(resolution = '110m', category = 'cultural', name = shapename)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection = ccrs.PlateCarree())\n",
    "ax.imshow(et_2017_anomaly, extent = extent, cmap = 'RdYlBu')\n",
    "ax.add_geometries(shpreader.Reader(states_shp).geometries(), ccrs.PlateCarree(), facecolor = 'none')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f04ad-61cd-40c5-8db1-a218161b48ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## More Resources\n",
    "\n",
    "- Curious about how to use `earthaccess.open()` along with `xarray` so that you don't have keep any downloaded files around? Well, `xarray.open_dataset()` can be slow when you have a lot of files to open, as in this time-series example. [This article describes how you can speed up `xarray.open_dataset()`](https://climate-cms.org/posts/2018-09-14-dask-era-interim.html) when working with multiple cloud-hosted files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
